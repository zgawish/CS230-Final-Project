{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Monkey Arm Movememnts via Electrode Signals"
      ],
      "metadata": {
        "id": "l3Qn4oDHJKpd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXGsTV4n9dXV"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JACNpCD2tkB4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "!pip install --upgrade tsmoothie\n",
        "from tsmoothie.smoother import LowessSmoother"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mf6gCVL9i3o"
      },
      "source": [
        "Connect dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQtYv9EotvKC"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "path = \"drive/MyDrive/CS230_Project/Jenkins_Rstruct_Data\"\n",
        "!ls $path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8CmWhPZ-r94"
      },
      "source": [
        "## Dataset information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3kdea-8t0xB"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "R = sio.loadmat(path+\"/JR_2015-12-04_truncated2.mat\")[\"R\"][0]\n",
        "ntrials = len(R)\n",
        "shape = R[0]['spikeRaster'].todense().shape\n",
        "fields = R[0].dtype.names\n",
        "\n",
        "print(\"There are %d trials in the R-struct\" % ntrials)\n",
        "print(\"There are %d electrodes with %d millseconds of data \\n\" % (shape[0], shape[1]))\n",
        "print(\"Fields in this dataset include: \")\n",
        "for field in fields:\n",
        "    print(\"-\", field)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fields we care about the most are `target` and `spikeRaster`.\n",
        "\n",
        "The `target` field holds the coordinates of the reach direction of a given trial.\n",
        "```python\n",
        "# returns a tuple indicating the x, y, and z coordinates\n",
        "# of the target reach direction for trial 0\n",
        "R[0]['target']\n",
        "```\n",
        "The `spikeRaster` field holds a sparse matrix where each row corresponds to an electrode, and each column corresponds to a spike time. We will use the `.todense()` function to convert the row to an array of 1s and 0s where each index is a millisecond indicating whether a neuron fired (1) or not (0).\n",
        "```python\n",
        "# returns an array of spikes for the first trial and\n",
        "# and the first electrode\n",
        "R[0]['spikeRaster'].todense()[0, :]\n",
        "# returns whether there was a spike for the first trial and\n",
        "# and the first electrode during the 10th millisecond\n",
        "R[0]['spikeRaster'].todense()[0,9]\n",
        "```"
      ],
      "metadata": {
        "id": "bmUFt5hF-z-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 9 possible reach directions.\n",
        "```python\n",
        "# Targets sorted in CCW\n",
        "xy_sorted = np.array([\n",
        "             [0.0, 0.0],          # 0\n",
        "             [120.0, 0.0],          # 1\n",
        "             [84.85, 84.85],        # 2\n",
        "             [0.0,   120.0],        # 3\n",
        "             [-84.85,84.85],        # 4\n",
        "             [-120.0, 0],           # 5\n",
        "             [-84.85, -84.85],      # 6\n",
        "             [0.0, -120],           # 7\n",
        "             [84.85,-84.85]])       # 8\n",
        "```"
      ],
      "metadata": {
        "id": "wE6wrHE4pwvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Raster plot of the data"
      ],
      "metadata": {
        "id": "Um84EPQY_h2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotRaster(S):\n",
        "    \"\"\"\n",
        "    plotRaster:\n",
        "    -----------\n",
        "    - S: spike train\n",
        "    -----------\n",
        "    - creates a raster plot of the spikes\n",
        "    \"\"\"\n",
        "    gap = 3\n",
        "    mark = 5\n",
        "    pad = 30\n",
        "    numSpikeTrain = len(S);\n",
        "    plt.figure()\n",
        "    for s in range(numSpikeTrain):\n",
        "        offset = pad + gap + s*(gap+mark);\n",
        "        train = S[s]\n",
        "        for t in train:\n",
        "            plt.plot([t, t], [offset, offset+mark],'black')\n",
        "        \n",
        "    plt.xlabel('Time (ms)')\n",
        "    plt.ylim([0,offset+mark+gap+pad])\n",
        "    plt.yticks([])\n",
        "    plt.grid(axis='x')"
      ],
      "metadata": {
        "id": "gs4BtQOK_gzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_reaches = 32\n",
        "electrode_number = 17\n",
        "spike_train = np.zeros((num_reaches), dtype=object)\n",
        "ix = 0\n",
        "for trial in R:\n",
        "    target = trial[\"target\"]\n",
        "    \n",
        "    if (target[0]==120 and target[1] == 0):\n",
        "        spike_train[ix] =  np.where(trial[\"spikeRaster\"].todense()[electrode_number - 1,:])[1]\n",
        "        ix += 1\n",
        "    \n",
        "plotRaster(spike_train);\n",
        "plt.xlabel('Time [ms]')\n",
        "plt.ylabel('Spikes by trial')\n",
        "plt.title('Raster Plot for Electrode 17')"
      ],
      "metadata": {
        "id": "WuMH8WkI_Q39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvICL4f1a5pB"
      },
      "source": [
        "## Restructure the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seperate data per reach, shift middle reaches, and apply pretraining"
      ],
      "metadata": {
        "id": "SjX1wjlEEaL3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0YARmeXD6u9"
      },
      "outputs": [],
      "source": [
        "def seperate_reaches(R, n_reach_trials, num_electrodes, ms_start, ms, reaches, middle_reach={}, shift_middle=True):\n",
        "    \"\"\"\n",
        "    seperate_reaches:\n",
        "    -----------------\n",
        "    - R: neural data\n",
        "    - n_reach_trials: number of trials we care about\n",
        "    - num_electrodes: number of electrodes we want to account for\n",
        "    - ms_start: start index of timeseries spikes\n",
        "    - ms: length of timeseries\n",
        "    - reaches: dict of possible reach directions (should have length of 8 if shift_middle is True)\n",
        "    - middle_reach: dict of mappings for shifting middle reaches\n",
        "    - shift_middle: boolean indicating if we want to shift the middle\n",
        "    -----------------\n",
        "    - Seprates data by reach direction\n",
        "    - Translates middle movements to reaches from previous point\n",
        "    \"\"\"\n",
        "    if shift_middle and len(reaches) == 9:\n",
        "        raise Exception(\"shift_middle is true which means len(reaches) should be 8\")\n",
        "    if not shift_middle and len(reaches) == 8:\n",
        "        raise Exception(\"shift_middle is false which means len(reaches) should be 9\")\n",
        "    spike_times = np.ndarray(shape=(n_reach_trials, num_electrodes, ms))\n",
        "    # pre training\n",
        "    smoother = LowessSmoother(smooth_fraction=0.1, iterations=1)\n",
        "    print(spike_times[0])\n",
        "    smoother.smooth(spike_times[0])\n",
        "    targets = np.ndarray(shape=(n_reach_trials, 1), dtype=int)\n",
        "\n",
        "    count = {} # verify counts per reach\n",
        "    per_reach = {} # seperate spikes per reach\n",
        "    prev = (round(R[0]['target'][0].item(), 2), round(R[0]['target'][1].item(), 2))\n",
        "\n",
        "    total = 0\n",
        "    for n in range(n_reach_trials):\n",
        "        spike_time = R[n]['spikeRaster'].todense()[:, ms_start: ms_start + ms]\n",
        "        target_x = round(R[n]['target'][0].item(), 2)\n",
        "        target_y = round(R[n]['target'][1].item(), 2)\n",
        "        # first check if middle\n",
        "        if target_x == round(0.0, 2) and target_y == round(0.0, 2) and shift_middle:\n",
        "            target_x = round(middle_reach_dict[prev[0]], 2)\n",
        "            target_y = round(middle_reach_dict[prev[1]], 2)\n",
        "        for d, dir in enumerate(reaches):\n",
        "            if target_x == round(dir[0], 2) and target_y == round(dir[1], 2):\n",
        "                prev = (target_x, target_y)\n",
        "                if d not in count:\n",
        "                    count[d] = 0\n",
        "                    per_reach[d] = []\n",
        "                per_reach[d].append(spike_time)\n",
        "                count[d] += 1\n",
        "                # col[d] = 1\n",
        "                targets[total, :] = d\n",
        "                spike_times[total, :, :] = spike_time\n",
        "                total += 1\n",
        "                break\n",
        "    return spike_times, targets, count, per_reach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHVkZ4lKoiEy"
      },
      "outputs": [],
      "source": [
        "n_reach_trials = ntrials - 1 # remove first middle reach\n",
        "num_electrodes = 96\n",
        "ms = 300\n",
        "ms_start = 200\n",
        "\n",
        "xy_sorted = np.array([\n",
        "             [120.0, 0.0],\n",
        "             [84.85, 84.85],\n",
        "             [0.0, 120.0],\n",
        "             [-84.85,84.85],\n",
        "             [-120.0, 0],\n",
        "             [-84.85, -84.85],\n",
        "             [0.0, -120],\n",
        "             [84.85,-84.85]])\n",
        "xy_sorted_middle = np.array([\n",
        "             [0.0, 0.0],\n",
        "             [120.0, 0.0],\n",
        "             [84.85, 84.85],\n",
        "             [0.0, 120.0],\n",
        "             [-84.85,84.85],\n",
        "             [-120.0, 0],\n",
        "             [-84.85, -84.85],\n",
        "             [0.0, -120],\n",
        "             [84.85,-84.85]])\n",
        "middle_reach_dict = {\n",
        "    0.0: 0.0,\n",
        "    -84.85: 84.85,\n",
        "    84.85: -84.85,\n",
        "    -120.0: 120.0,\n",
        "    120.0: -120.0,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4wxmyD0ztFk"
      },
      "outputs": [],
      "source": [
        "spike_times, targets, count, per_reach = seperate_reaches(R, n_reach_trials, num_electrodes, ms_start, ms, xy_sorted, middle_reach_dict, shift_middle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oHsvwkVyAx5"
      },
      "outputs": [],
      "source": [
        "spike_times.shape, targets.shape, count, len(per_reach) # verify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PDeaYGQW-Kg"
      },
      "source": [
        "### Evenly Sample From Each Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTgNLEVXE8pH"
      },
      "outputs": [],
      "source": [
        "import sklearn.model_selection as sk\n",
        "\n",
        "def even_sample(train_size, n_reach_trials, num_electrodes, ms, count, per_reach):\n",
        "    # get num_train and num_test manually b/c of rounding errors\n",
        "    num_train = 0\n",
        "    num_test = 0\n",
        "    for c in count:\n",
        "        num_train += int(train_size * count[c])\n",
        "        num_test += int((1 - train_size) * count[c])\n",
        "    print(num_train, num_test, n_reach_trials - num_train)\n",
        "    # initialize training and test sets\n",
        "    X_train = np.ndarray(shape=(num_train, num_electrodes, ms))\n",
        "    X_test = np.ndarray(shape=(n_reach_trials - num_train, num_electrodes, ms))\n",
        "    Y_train = np.ndarray(shape=(num_train, 1), dtype=int)\n",
        "    Y_test = np.ndarray(shape=(n_reach_trials - num_train, 1), dtype=int)\n",
        "\n",
        "    train_start = 0\n",
        "    test_start = 0\n",
        "    test = 0\n",
        "    train = 0\n",
        "    for d in per_reach:\n",
        "        reach = np.array(per_reach[d])\n",
        "        target = np.full((reach.shape[0], 1), d)\n",
        "        reach_x_train, reach_x_test, reach_y_train, reach_y_test = sk.train_test_split(reach, target, train_size=train_size, random_state = 42)\n",
        "        train += len(reach_y_train)\n",
        "        test += len(reach_y_test)\n",
        "        X_train[train_start: train_start + reach_x_train.shape[0], :, :] = reach_x_train\n",
        "        X_test[test_start: test_start + reach_x_test.shape[0], :, :] = reach_x_test\n",
        "        Y_train[train_start: train_start + reach_y_train.shape[0], :] = reach_y_train\n",
        "        Y_test[test_start: test_start + reach_y_test.shape[0], :] = reach_y_test\n",
        "        train_start += reach_x_train.shape[0]\n",
        "        test_start += reach_x_test.shape[0]\n",
        "    return X_train, Y_train, X_test[:test], Y_test[:test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3S3rrzr2pk-"
      },
      "outputs": [],
      "source": [
        "raw_x_train, raw_y_train, raw_x_test, raw_y_test = even_sample(.7, n_reach_trials, num_electrodes, ms, count, per_reach)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_x_train.shape"
      ],
      "metadata": {
        "id": "fN-NZEGONgr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdvJ74A5XnmP"
      },
      "source": [
        "### Reshape data and apply one-hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation, Flatten\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "I8pWgPVC92hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "X_train_base = tf.cast(deepcopy(raw_x_train), tf.float32)\n",
        "X_test_base = tf.cast(deepcopy(raw_x_test), tf.float32)"
      ],
      "metadata": {
        "id": "JogIzeIULZIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bER6Rik02dKC"
      },
      "outputs": [],
      "source": [
        "X_train = tf.reshape(raw_x_train, (raw_x_train.shape[0], raw_x_train.shape[2], raw_x_train.shape[1]))\n",
        "X_test = tf.reshape(raw_x_test, (raw_x_test.shape[0], raw_x_test.shape[2], raw_x_test.shape[1]))\n",
        "X_train = tf.cast(X_train, tf.float32)\n",
        "X_test = tf.cast(X_test, tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wysRhnArN7bh"
      },
      "outputs": [],
      "source": [
        "Y_train = []\n",
        "for t in range(raw_y_train.shape[0]):\n",
        "    col = np.zeros((len(per_reach),))\n",
        "    col[raw_y_train[t][0]] = 1\n",
        "    Y_train.append(col)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "Y_test = []\n",
        "for t in range(raw_y_test.shape[0]):\n",
        "    col = np.zeros((len(per_reach),))\n",
        "    col[raw_y_test[t][0]] = 1\n",
        "    Y_test.append(col)\n",
        "Y_test = np.array(Y_test)\n",
        "\n",
        "Y_train.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1QizCu30cPP"
      },
      "outputs": [],
      "source": [
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA2gb0Hkv_aR"
      },
      "outputs": [],
      "source": [
        "Y_train_base = deepcopy(Y_train)\n",
        "Y_test_base = deepcopy(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_base.shape, Y_train_base.shape, X_test_base.shape, Y_test_base.shape"
      ],
      "metadata": {
        "id": "XbGFYgTLNQuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric functions"
      ],
      "metadata": {
        "id": "syYwaG3oFsFs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpN-dS-nt488"
      },
      "outputs": [],
      "source": [
        "def recall(y_true, y_pred):\n",
        "    y_true = np.ones_like(y_true)\n",
        "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
        "    all_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n",
        "\n",
        "    recall = true_positives / (all_positives + np.finfo(float).eps)\n",
        "    return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    y_true = np.ones_like(y_true)\n",
        "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + np.finfo(float).eps)\n",
        "    return precision\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2*((p*r)/(p+r+np.finfo(float).eps))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model"
      ],
      "metadata": {
        "id": "Xy3RkF4JLJKu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv2Fdt1g4tFr"
      },
      "outputs": [],
      "source": [
        "def Neuro(input_shape, num_catagories, l1, l2):\n",
        "    \"\"\"\n",
        "    LSTM -> LSTM -> Dense -> Softmax\n",
        "    Arguments:\n",
        "    input_shape    -- shape of the input, usually (max_len,)\n",
        "    num_catagories -- number of catagories (8 or 9)\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    input = Input(input_shape, dtype='float32')\n",
        "    X = LSTM(l1, return_sequences=True)(input) \n",
        "    X = Dropout(.7)(X) \n",
        "    X = LSTM(l2, return_sequences=False)(X)  \n",
        "    X = Dropout(.7)(X)\n",
        "    X = Dense(num_catagories)(X) \n",
        "    X = Activation('softmax')(X)\n",
        "    \n",
        "    model = Model(input, X)\n",
        "    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "5L6uHnjBIMTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5cRLxPN0GkS"
      },
      "outputs": [],
      "source": [
        "model = Neuro((ms, num_electrodes), len(per_reach), 64, 64)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, epochs=40, batch_size = 5, shuffle=True, validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFw5X0ey0e_l"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_test, Y_test)\n",
        "print(\"Test accuracy = \", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "x-uG_TqoIPuI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw5NECinWwiE"
      },
      "outputs": [],
      "source": [
        "# verify test\n",
        "preds = model.predict(X_test)\n",
        "wrongs = {}\n",
        "rights = {}\n",
        "for i in range(len(preds)):\n",
        "    pred = preds[i]\n",
        "    test = Y_test[i]\n",
        "    a = np.argmax(pred)\n",
        "    b = np.argmax(test)\n",
        "    if a == b:\n",
        "        if b not in rights:\n",
        "            rights[b] = 0\n",
        "        rights[b] += 1\n",
        "    else:\n",
        "        if b not in wrongs:\n",
        "            wrongs[b] = 0\n",
        "        wrongs[b] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy per reach"
      ],
      "metadata": {
        "id": "rHS5zRFcItKZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owVUZJohJjSF"
      },
      "outputs": [],
      "source": [
        "for wrong in wrongs:\n",
        "    r = rights.get(wrong, 0)\n",
        "    w = wrongs.get(wrong, 0)\n",
        "    c = count.get(wrong, 0)\n",
        "    print(\"reach {} right: {} wrong: {} count: {} acc: {}\".format(wrong, r, w, c, r / c))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top K results"
      ],
      "metadata": {
        "id": "eB8bK9BJImxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = tf.keras.metrics.top_k_categorical_accuracy(Y_test, preds, k=3)\n",
        "np.sum(m) / len(m)"
      ],
      "metadata": {
        "id": "q2bexPfkGZvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z8uadoWgqVb"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.metrics import confusion_matrix\n",
        "conf = tf.compat.v1.confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(preds, axis=1), num_classes=len(per_reach))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision and Recall"
      ],
      "metadata": {
        "id": "UDZHmn1DVZqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WD94GbNQh89P"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, precision_recall_curve, average_precision_score, PrecisionRecallDisplay, f1_score\n",
        "\n",
        "labels = [\"E\", \"NE\", \"N\", \"NW\", \"W\", \"SW\", \"S\", \"SE\"]\n",
        "\n",
        "# recall \n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=np.array(conf), display_labels=labels)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "\n",
        "# percision\n",
        "print(\"Precision per class: \", precision_score(np.argmax(Y_test, axis=1), np.argmax(preds, axis=1), average=None, sample_weight=None, zero_division='warn'))\n",
        "print(\"Overall Precision: \", precision_score(np.argmax(Y_test, axis=1), np.argmax(preds, axis=1), average='micro', sample_weight=None, zero_division='warn'))\n",
        "\n",
        "# recall and precision score\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "average_precision = dict()\n",
        "for i in range(len(labels) - 1):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i], preds[:, i])\n",
        "    average_precision[i] = average_precision_score(Y_test[:, i], preds[:, i])\n",
        "\n",
        "# A \"micro-average\": quantifying score on all classes jointly\n",
        "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(\n",
        "    Y_test.ravel(), preds.ravel()\n",
        ")\n",
        "average_precision[\"micro\"] = average_precision_score(Y_test, preds, average=\"micro\")\n",
        "display = PrecisionRecallDisplay(\n",
        "    recall=recall[\"micro\"],\n",
        "    precision=precision[\"micro\"],\n",
        "    average_precision=average_precision[\"micro\"],\n",
        ")\n",
        "display.plot()\n",
        "_ = display.ax_.set_title(\"Precision vs. Recall over all classes\")\n",
        "\n",
        "# f1 score\n",
        "print(\"f1 score: \", f1_score(np.argmax(Y_test, axis=1), np.argmax(preds, axis=1), labels=None, pos_label=1, average='micro', sample_weight=None, zero_division='warn'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}